{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS2545 - Term Mini-Project\n",
    "\n",
    "### CS2545 - Data Science ###\n",
    "### Winter, 2025 ###\n",
    "### UNB, Fredericton ###\n",
    "\n",
    "Refer to the read me for more details on the project.\n",
    "</br>\n",
    "</br>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries & Save File paths for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the goodies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ploting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import openpyxl as pxl\n",
    "\n",
    "\n",
    "# All Data to import using dataframes\n",
    "population_Data_Path = \"../data/population.csv\"\n",
    "Electricity_Generation_Data_Path = \"../data/Electricity_Generation.xlsx\"\n",
    "Electricity_Interchange_Data_Path = \"../data/Electricity_Interchange.xlsx\"\n",
    "Electricity_Capacity_Data_Path = \"../data/Electricity_Capacity.xlsx\"\n",
    "End_Use_Demand_Data_Path = \"../data/End_Use_Demand.xlsx\"\n",
    "End_Use_Prices_Data_Path = \"../data/End_Use_Prices.xlsx\"\n",
    "energy_trade_canada_path = \"../data/energy_trade_canada.xls\"\n",
    "Canadian_Climate_Normals_CANADA_Data_Path = \"../data/1991-2020_Canadian_Climate_Normals_CANADA_Data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# CSV files\n",
    "population_df = pd.read_csv(population_Data_Path, skiprows=6)\n",
    "climate_df = pd.read_csv(Canadian_Climate_Normals_CANADA_Data_Path, sep=\",\")\n",
    "\n",
    "# # Excel Files\n",
    "generation_df = pd.read_excel(Electricity_Generation_Data_Path)\n",
    "capacity_df = pd.read_excel(Electricity_Capacity_Data_Path)\n",
    "interchange_df = pd.read_excel(Electricity_Interchange_Data_Path)\n",
    "demand_df = pd.read_excel(End_Use_Demand_Data_Path)\n",
    "prices_df = pd.read_excel(End_Use_Prices_Data_Path)\n",
    "# prtrade_df = pd.read_excel(energy_trade_canada_path)\n",
    "\n",
    "\n",
    "dataframes = {\n",
    "    \"Population\": population_df,\n",
    "    \"Generation\": generation_df,\n",
    "    \"Capacity\": capacity_df,\n",
    "    \"Interchange\": interchange_df,\n",
    "    \"Demand\": demand_df,\n",
    "    \"Prices\": prices_df,\n",
    "    \"Climate\": climate_df\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Generation Data Set Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_generation(df, start_row, province_name, num_rows = 8):\n",
    "\n",
    "    header_row = start_row + 1\n",
    "    data_rows = start_row + 2\n",
    "\n",
    "    headers = df.iloc[header_row]\n",
    "    block = df.iloc[data_rows : data_rows + num_rows].copy()\n",
    "    block.columns = headers\n",
    "\n",
    "    block = block.dropna(subset=[block.columns[0]])\n",
    "\n",
    "    block = block.rename(columns={block.columns[0]: \"Energy_Type\"})\n",
    "    block = block.melt(id_vars=\"Energy_Type\", var_name=\"Year\", value_name=\"GWh\")\n",
    "\n",
    "    block[\"Province\"] = province_name\n",
    "    block[\"Year\"] = pd.to_numeric(block[\"Year\"], errors=\"coerce\")\n",
    "    block[\"GWh\"] = pd.to_numeric(block[\"GWh\"], errors=\"coerce\")\n",
    "\n",
    "    block = block.dropna(subset=[\"Year\", \"GWh\"])\n",
    "    block[\"Year\"] = block[\"Year\"].astype(int)\n",
    "\n",
    "    return block\n",
    "\n",
    "provinces_generation = {\n",
    "    \"Canada\": 5,\n",
    "    \"Newfoundland and Labrador\": 16,\n",
    "    \"Prince Edward Island\": 27,\n",
    "    \"Nova Scotia\": 38,\n",
    "    \"New Brunswick\": 49,\n",
    "    \"Quebec\": 60,\n",
    "    \"Ontario\": 71,\n",
    "    \"Manitoba\": 82,\n",
    "    \"Alberta\": 93,\n",
    "    \"British Columbia\": 104,\n",
    "    \"Saskatchewan\": 115,\n",
    "    \"Yukon\": 126,\n",
    "    \"Northwest Territories\": 137,\n",
    "    \"Nunavut\": 148,\n",
    "}\n",
    "\n",
    "all_province_data = []\n",
    "\n",
    "for province, start_row in provinces_generation.items():\n",
    "    cleaned = clean_generation(generation_df, start_row, province)\n",
    "    all_province_data.append(cleaned)\n",
    "\n",
    "\n",
    "gen_clean = pd.concat(all_province_data, ignore_index=True)\n",
    "quebec_df = gen_clean[gen_clean[\"Province\"] == \"Canada\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Capacity Data Set Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Im using the same function from generation data\n",
    "\n",
    "provinces_cap = {\n",
    "    \"Canada\": 5,\n",
    "    \"Newfoundland and Labrador\": 16,\n",
    "    \"Prince Edward Island\": 27,\n",
    "    \"Nova Scotia\": 38,\n",
    "    \"New Brunswick\": 49,\n",
    "    \"Quebec\": 60,\n",
    "    \"Ontario\": 71,\n",
    "    \"Manitoba\": 82,\n",
    "    \"Alberta\": 93,\n",
    "    \"British Columbia\": 104,\n",
    "    \"Saskatchewan\": 115,\n",
    "    \"Yukon\": 126,\n",
    "    \"Northwest Territories\": 137,\n",
    "    \"Nunavut\": 148,\n",
    "}\n",
    "\n",
    "all_province_cap_data = []\n",
    "for province, start_row in provinces_cap.items():\n",
    "    cap_cleaned = clean_generation(capacity_df, start_row, province)\n",
    "    all_province_cap_data.append(cap_cleaned)\n",
    "\n",
    "cap_clean = pd.concat(all_province_cap_data, ignore_index=True)\n",
    "# cap_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Interchange Data Set Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in interchange_df: 102\n"
     ]
    }
   ],
   "source": [
    "# Im gonna reuse the same function as well\n",
    "print(\"Total rows in interchange_df:\", len(interchange_df))\n",
    "provinces_interchange = {\n",
    "    \"Canada\": 5,\n",
    "    \"Newfoundland and Labrador\": 14,\n",
    "    \"Prince Edward Island\": 23,\n",
    "    \"Nova Scotia\": 32,\n",
    "    \"New Brunswick\": 41,\n",
    "    \"Quebec\": 50,\n",
    "    \"Ontario\": 59,\n",
    "    \"Manitoba\": 68,\n",
    "    \"Alberta\": 77,\n",
    "    \"British Columbia\": 86,\n",
    "    \"Saskatchewan\": 95,\n",
    "}\n",
    "\n",
    "all_province_interchange_data = []\n",
    "for province, start_row in provinces_interchange.items():\n",
    "    clean_interchange_block = clean_generation(interchange_df, start_row, province)\n",
    "    all_province_interchange_data.append(clean_interchange_block)\n",
    "\n",
    "interchange_clean = pd.concat(all_province_interchange_data, ignore_index=True)\n",
    "# display(interchange_clean)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End use demand data set cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_end_use_demand(df, sector_blocks, num_rows=7):\n",
    "    all_sectors = []\n",
    "\n",
    "    for sector, start_row in sector_blocks.items():\n",
    "        header_row = start_row + 1\n",
    "        data_start = start_row + 2\n",
    "\n",
    "        headers = df.iloc[header_row]\n",
    "        block = df.iloc[data_start : data_start + num_rows].copy()\n",
    "        block.columns = headers\n",
    "\n",
    "        block = block.dropna(subset=[block.columns[0]])\n",
    "        block = block.rename(columns={block.columns[0]: \"Energy_Type\"})\n",
    "\n",
    "        block = block.melt(id_vars=\"Energy_Type\", var_name=\"Year\", value_name=\"PJ\")\n",
    "        block[\"Sector\"] = sector\n",
    "        block[\"Year\"] = pd.to_numeric(block[\"Year\"], errors=\"coerce\")\n",
    "        block[\"PJ\"] = pd.to_numeric(block[\"PJ\"], errors=\"coerce\")\n",
    "\n",
    "        block = block.dropna(subset=[\"Year\", \"PJ\"])\n",
    "        block[\"Year\"] = block[\"Year\"].astype(int)\n",
    "\n",
    "        all_sectors.append(block)\n",
    "\n",
    "    return pd.concat(all_sectors, ignore_index=True)\n",
    "\n",
    "\n",
    "sector_blocks = {\n",
    "    \"Total End-Use\": 5,\n",
    "    \"Residential\": 14,\n",
    "    \"Commercial\": 23,\n",
    "    \"Industrial\": 32,\n",
    "    \"Transportation\": 41\n",
    "}\n",
    "demand_clean = clean_end_use_demand(demand_df, sector_blocks)\n",
    "# display(demand_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End use Price data set cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in prices_df: 82\n"
     ]
    }
   ],
   "source": [
    "print(\"Total rows in prices_df:\", len(prices_df))\n",
    "\n",
    "prices_provinces = {\n",
    "    \"Newfoundland and Labrador\": 5,\n",
    "    \"Prince Edward Island\": 11,\n",
    "    \"Nova Scotia\": 17,\n",
    "    \"New Brunswick\": 23,\n",
    "    \"Quebec\": 29,\n",
    "    \"Ontario\": 35,\n",
    "    \"Manitoba\": 41,\n",
    "    \"Alberta\": 47,\n",
    "    \"British Columbia\": 53,\n",
    "    \"Saskatchewan\": 59,\n",
    "    \"Yukon\": 65,\n",
    "    \"Northwest Territories\": 71,\n",
    "    \"Nunavut\": 77,\n",
    "}\n",
    "\n",
    "\n",
    "all_province_price_data = []\n",
    "\n",
    "for province, start_row in prices_provinces.items():\n",
    "    clean_block = clean_generation(prices_df, start_row, province, num_rows=3)\n",
    "    all_province_price_data.append(clean_block)\n",
    "\n",
    "prices_clean = pd.concat(all_province_price_data, ignore_index=True)\n",
    "# display(prices_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate Data Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_climate_data(df):\n",
    "\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df_yearly = df.copy()\n",
    "    df_yearly = df_yearly.rename(columns={\n",
    "        \"LOCATION_NAME\": \"Location\",\n",
    "        \"PROVINCE_OR_TERRITORY\": \"Province\",\n",
    "        \"NORMALS_ELEMENT\": \"Element\",\n",
    "        \"Year\": \"Value\"\n",
    "    })\n",
    "\n",
    "    df_yearly[\"Value\"] = pd.to_numeric(df_yearly[\"Value\"], errors=\"coerce\")\n",
    "    df_yearly = df_yearly.dropna(subset=[\"Value\"])\n",
    "\n",
    "    df_yearly = df_yearly[~df_yearly[\"Element\"].str.contains(\"Date|StdDev|Extreme\", na=False)]\n",
    "\n",
    "    return df_yearly[[\"Location\", \"Province\", \"PERIOD_OF_RECORD\", \"ELEMENT_GROUP\", \"Element\", \"Value\"]]\n",
    "\n",
    "\n",
    "climate_clean = clean_climate_data(climate_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population Data Set Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (24, 1)\n",
      "After header fix: (23, 1)\n",
      "Columns: ['Province'] ...\n",
      "Melted shape: (0, 3)\n",
      "Empty DataFrame\n",
      "Columns: [Province, Quarter, Population]\n",
      "Index: []\n",
      "Unique years extracted: []\n",
      "Final shape: (0, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Province",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Population",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8e69ea13-781a-43e4-891a-f3ae6da63865",
       "rows": [],
       "shape": {
        "columns": 3,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province</th>\n",
       "      <th>Year</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Province, Year, Population]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def debug_clean_population_quarterly(df):\n",
    "    # Step 1: Check initial shape\n",
    "    print(\"Initial shape:\", df.shape)\n",
    "\n",
    "    # Step 2: Fix headers\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    print(\"After header fix:\", df.shape)\n",
    "\n",
    "    # Step 3: Rename first column\n",
    "    df = df.rename(columns={df.columns[0]: \"Province\"})\n",
    "    print(\"Columns:\", df.columns.tolist()[:5], \"...\")  # preview\n",
    "\n",
    "    # Step 4: Melt to long format\n",
    "    df_long = df.melt(id_vars=\"Province\", var_name=\"Quarter\", value_name=\"Population\")\n",
    "    print(\"Melted shape:\", df_long.shape)\n",
    "    print(df_long.head(3))\n",
    "\n",
    "    # Step 5: Extract year\n",
    "    df_long[\"Year\"] = df_long[\"Quarter\"].str.extract(r\"(\\d{4})\")\n",
    "    print(\"Unique years extracted:\", df_long[\"Year\"].dropna().unique()[:5])\n",
    "    \n",
    "    # Step 6: Drop invalid years\n",
    "    df_long = df_long.dropna(subset=[\"Year\"])\n",
    "    df_long[\"Year\"] = df_long[\"Year\"].astype(int)\n",
    "\n",
    "    # Step 7: Clean population numbers\n",
    "    df_long[\"Population\"] = df_long[\"Population\"].astype(str).str.replace(\",\", \"\", regex=False).astype(float)\n",
    "\n",
    "    # Step 8: Group by year/province\n",
    "    df_yearly = df_long.groupby([\"Province\", \"Year\"], as_index=False).agg({\"Population\": \"mean\"})\n",
    "    print(\"Final shape:\", df_yearly.shape)\n",
    "\n",
    "    return df_yearly\n",
    "\n",
    "population_yearly_df = debug_clean_population_quarterly(population_df)\n",
    "display(population_yearly_df.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
